<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <title>AIéŸ³å£°å…¥åŠ›ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆUI (æ–‡ç« èª­ã¿ä¸Šã’ç‰ˆ)</title>
    <style>
        body {
            margin: 0;
            background: #0f0f0f;
            font-family: 'Segoe UI', sans-serif;
            overflow: hidden;
        }

        /* 1. æ³¢å½¢ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã®èƒŒæ™¯ */
        #waveCanvas {
            position: fixed;
            top: 0; left: 0;
            width: 100vw;
            height: 100vh;
            z-index: 0;
        }

        /* 2. UIã‚³ãƒ³ãƒ†ãƒŠã®èª¿æ•´ (ä¸‹éƒ¨ã«å›ºå®š) */
        #ui {
            position: absolute;
            bottom: 5%;
            left: 50%;
            transform: translateX(-50%);
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 1.5rem;
            z-index: 10;
        }

        /* 3. ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚¨ãƒªã‚¢ã®å®šç¾© */
        #status-area {
            padding: 15px 30px;
            background: rgba(0, 0, 0, 0.5);
            border-radius: 12px;
            backdrop-filter: blur(5px);
            box-shadow: 0 0 20px rgba(0, 255, 255, 0.3);
            color: #00ffff;
            font-size: 1.5rem;
            font-weight: bold;
            min-height: 40px; 
            display: flex;
            align-items: center;
            justify-content: center;
        }
        
        /* 4. å…¥åŠ›ã¨ãƒœã‚¿ãƒ³ã®ã‚¹ã‚¿ã‚¤ãƒ« */
        #input-controls {
            display: flex;
            gap: 1rem;
        }
        #messageInput {
            width: 400px;
            padding: 1rem;
            font-size: 1.2rem;
            background: rgba(255, 255, 255, 0.05);
            border: 1px solid rgba(0, 255, 255, 0.5);
            color: #fff;
            border-radius: 8px;
            backdrop-filter: blur(10px);
            outline: none;
        }
        #messageInput::placeholder {
            color: rgba(255, 255, 255, 0.4);
        }
        #sendBtn {
            padding: 1rem 2rem;
            font-size: 2.2rem;
            color: #0f0f0f;
            background: #00ffff;
            border: none;
            border-radius: 16px;
            cursor: pointer;
            backdrop-filter: blur(10px);
            transition: background 0.3s;
            box-shadow: 0 0 40px #00ffff;
        }
        #sendBtn:hover {
            background: #33ffff;
        }

        #sendBtn {
            /* æ–‡å­—ã‚µã‚¤ã‚ºã‚’å°ã•ãã™ã‚‹ */
            font-size: 8px; 
            /* ãƒœã‚¿ãƒ³å†…ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¸­å¤®æƒãˆã«ã™ã‚‹ (ä»»æ„) */
            text-align: center;
            /* ãƒœã‚¿ãƒ³ã®å¹…ã‚’ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã«åˆã‚ã›ã‚‹ */
            width: auto; 
            padding: 25px 35px; /* ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã‚’èª¿æ•´ã—ã¦è¦‹ã‚„ã™ã */
        }
    </style>
</head>
<body>
    <canvas id="waveCanvas"></canvas>
    
    <div id="ui">
        <!-- <div id="status-area">
            ã‚¤ãƒã‚¸ãƒŠãƒªãƒ¼ãƒŠãƒ³ãƒãƒ¼   \n +
            é€šç§°GAIã‚¤ãƒã•ã‚“  AI \n +
            AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆå¾…æ©Ÿä¸­...
        </div> -->

        <div id="status-area" >
            ã‚¤ãƒã‚¸ãƒŠãƒªãƒ¼ãƒŠãƒ³ãƒãƒ¼<br>
            é€šç§°GAIã‚¤ãƒã•ã‚“AI<br>
            AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆå¾…æ©Ÿä¸­...
        </div>

        <div id="input-controls">
            <input type="text" id="messageInput" placeholder="ã“ã“ã«æ–‡ç« ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„" value="">
            <!-- <button id="sendBtn">ã‚¤ãƒã‚¸ãƒŠãƒªãƒ¼ãƒŠãƒ³ãƒãƒ¼<br>
            é€šç§°GAIã‚¤ãƒã•ã‚“AIã‚’<br>ãƒªã‚»ãƒƒãƒˆã™ã‚‹</button> -->
            <button id="sendBtn">
                ã‚¤ãƒã‚¸ãƒŠãƒªãƒ¼ãƒŠãƒ³ãƒãƒ¼<br>
                é€šç§°GAIã‚¤ãƒã•ã‚“AIã‚’<br>
                ãƒªã‚»ãƒƒãƒˆã™ã‚‹
            </button>
        </div>
    </div>

    <script>
        // --- 1. ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³é–¢é€£ ---
        const canvas = document.getElementById("waveCanvas");
        const ctx = canvas.getContext("2d");
        canvas.width = window.innerWidth;
        canvas.height = window.innerHeight;

        let bars = [];
        const barCount = 40;
        const barWidth = 8;
        const waveY = canvas.height / 2;
        let animationFrameId;
        let isSpeaking = false; 

        function createBars() {
            bars = [];
            const startX = canvas.width / 2 - (barCount * barWidth) / 2;
            for (let i = 0; i < barCount; i++) {
                bars.push({
                    x: startX + i * barWidth,
                    height: 10,
                    color: "#00ffff"
                });
            }
        }

        function drawBars() {
            bars.forEach(bar => {
                ctx.fillStyle = bar.color;
                ctx.fillRect(bar.x, waveY - bar.height / 2, barWidth - 2, bar.height); 
            });
        }

        function animateBars() {
            ctx.clearRect(0, 0, canvas.width, canvas.height);

            bars.forEach(bar => {
                let targetHeight;
                if (isSpeaking) {
                    // èª­ã¿ä¸Šã’ä¸­ã¯é«˜ã•ã‚’ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ã«å¤‰åŒ–ã•ã›ã‚‹
                    targetHeight = Math.random() * 80 + 20; 
                } else {
                    // å¾…æ©Ÿä¸­ã¯å¾ã€…ã«ä½ã„é™ã‹ãªçŠ¶æ…‹ã«æˆ»ã‚‹
                    targetHeight = 10 + Math.random() * 10;
                }
                
                // ã‚¹ãƒ ãƒ¼ã‚ºãªé·ç§»
                bar.height += (targetHeight - bar.height) * 0.15;
            });
            
            drawBars();
            animationFrameId = requestAnimationFrame(animateBars);
        }
        
        // --- 2. éŸ³å£°èª­ã¿ä¸Šã’é–¢é€£ ---
        const qrInput = document.getElementById("messageInput");
        const statusArea = document.getElementById("status-area");
        const sendBtn = document.getElementById("sendBtn");
        
        const synth = window.speechSynthesis;
        let utterance = null;
        let currentTextToSpeak = ''; // æœ€å¾Œã«èª­ã¿ä¸Šã’ã‚’é–‹å§‹ã—ãŸæ–‡ç« ã‚’ä¿æŒ

        // èª­ã¿ä¸Šã’ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã®æ›´æ–°
        function updateStatus(message, color = '#00ffff') {
            statusArea.textContent = message;
            statusArea.style.color = color;
            statusArea.style.boxShadow = `0 0 20px ${color}80`;
        }

        // å…¥åŠ›ã•ã‚ŒãŸæ–‡ç« å…¨ä½“ã‚’èª­ã¿ä¸Šã’ã‚‹é–¢æ•°
        function speakSentence(text) {
            // ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã‹ã€æ—¢ã«åŒã˜ãƒ†ã‚­ã‚¹ãƒˆã®èª­ã¿ä¸Šã’ãŒé–‹å§‹ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ä½•ã‚‚ã—ãªã„
            if (text.trim() === '' || text === currentTextToSpeak) {
                return;
            }

            // æ–°ã—ã„èª­ã¿ä¸Šã’ãŒé–‹å§‹ã•ã‚Œã‚‹ã®ã§ã€ç¾åœ¨ã®èª­ã¿ä¸Šã’ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
            if (synth.speaking) {
                synth.cancel();
            }
            
            currentTextToSpeak = text; // æ–°ã—ã„æ–‡ç« ã‚’è¨˜æ†¶

            utterance = new SpeechSynthesisUtterance(text);
            utterance.lang = 'ja-JP'; // æ—¥æœ¬èªã‚’è¨­å®š
            utterance.rate = 1.0; // èª­ã¿ä¸Šã’é€Ÿåº¦ã‚’æ¨™æº–ã«æˆ»ã™ (1æ–‡å­—ãšã¤ã§ã¯ãªã„ãŸã‚)

            utterance.onstart = () => {
                isSpeaking = true;
                
                // èª­ã¿ä¸Šã’ä¸­ã®æ–‡ç« ã‚’ä¸€éƒ¨è¡¨ç¤º
                const display = text.length > 20 ? text.substring(0, 20) + '...' : text;
                
                // ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒªãƒ†ãƒ©ãƒ« (ãƒãƒƒã‚¯ã‚¯ã‚©ãƒ¼ãƒˆ) ã‚’ä½¿ç”¨ã—ã¦å¤‰æ•°ã‚’åŸ‹ã‚è¾¼ã¿ã€3è¡Œã«æ•´å½¢
                const formattedStatus = `
            ã‚¤ãƒã‚¸ãƒŠãƒªãƒ¼ãƒŠãƒ³ãƒãƒ¼
            é€šç§°GAIã‚¤ãƒã•ã‚“AIå¿œç­”
            ã€Œ${display}ã€
            `;

                // updateStatusé–¢æ•°ã«ã¯ã€æ•´å½¢ã—ãŸæ–‡å­—åˆ—ã¨è‰²ã‚’å¼•æ•°ã§æ¸¡ã™
                // â€» updateStatusãŒç¬¬äºŒå¼•æ•°ã‚’ã‚«ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰ã¨ã—ã¦å—ã‘å–ã‚‹ã“ã¨ã‚’å‰æ
                updateStatus(formattedStatus, '#00ffaa');
            };
            utterance.onend = () => {
                isSpeaking = false;
                
                // ã“ã“ã§æ•´å½¢ã•ã‚ŒãŸæ–‡å­—åˆ—ã‚’å®šç¾©ãƒ»é©ç”¨
                const formattedStatus = (
                    "  ã‚¤ãƒã‚¸ãƒŠãƒªãƒ¼ãƒŠãƒ³ãƒãƒ¼   \n" +
                    "  é€šç§°GAIã‚¤ãƒã•ã‚“  AI \n" +
                    "ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆå¾…æ©Ÿä¸­..."
                );

                updateStatus(formattedStatus);
            };
            // utterance.onend = () => {
            //     isSpeaking = false;
            //     updateStatus('ã‚¤ãƒã‚¸ãƒŠãƒªãƒ¼ãƒŠãƒ³ãƒãƒ¼  é€šç§°GAIã‚¤ãƒã•ã‚“AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆå¾…æ©Ÿä¸­...');
            // };

            utterance.onerror = (event) => {
                console.error('Speech Synthesis Error:', event);
                isSpeaking = false;
                updateStatus('èª­ã¿ä¸Šã’ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ', '#ff0000');
            };

            synth.speak(utterance);
        }

        // å…¥åŠ›ã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼: æ–‡ç« å…¨ä½“ã‚’èª­ã¿ä¸Šã’ã‚‹ã‚ˆã†ã«å¤‰æ›´
        qrInput.addEventListener('input', (event) => {
            const currentText = qrInput.value;
            
            if (currentText.trim() !== "") {
                // å…¥åŠ›ã•ã‚ŒãŸæ–‡ç« å…¨ä½“ã‚’èª­ã¿ä¸Šã’é–¢æ•°ã«æ¸¡ã™
                speakSentence(currentText); 
            } else {
                // å…¨ã¦å‰Šé™¤ã•ã‚ŒãŸå ´åˆ
                if (synth.speaking) {
                    synth.cancel();
                }
                isSpeaking = false;
                currentTextToSpeak = '';
                updateStatus('AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆå¾…æ©Ÿä¸­...');
            }
        });
        
        // ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³ã®æ©Ÿèƒ½
        sendBtn.addEventListener("click", () => {
            qrInput.value = ""; // å…¥åŠ›æ¬„ã‚’ç©ºã«ã™ã‚‹
            if (synth.speaking) {
                synth.cancel(); // èª­ã¿ä¸Šã’ã‚’åœæ­¢
            }
            isSpeaking = false;
            currentTextToSpeak = '';
            updateStatus('ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸã€‚å…¥åŠ›ã‚’ãŠå¾…ã¡ã—ã¦ã„ã¾ã™...');
            qrInput.focus();
        });

        // --- 3. åˆæœŸåŒ– ---
        createBars();
        animateBars();
        qrInput.focus();
        updateStatus('AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆå¾…æ©Ÿä¸­...');
// Canvasç’°å¢ƒã§ã¯è‡ªå‹•ã§APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¾ã™ãŒã€ã“ã“ã§ã¯FastAPIã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã™ã‚‹ãŸã‚ã€ç©ºã®ã¾ã¾ã«ã—ã¾ã™ã€‚
const API_KEY = ""; 
// const GEMINI_MODEL = 'gemini-2.5-flash-preview-09-2025'; // ä¸è¦ (ã‚µãƒ¼ãƒãƒ¼å´ã§å®šç¾©)
// ğŸ’¡ LLM FastAPI ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®URL (gemini_backend.py ãŒãƒãƒ¼ãƒˆ8001ã§å‹•ä½œ)
const LLM_API_URL = "http://127.0.0.1:8001/generate";
// ğŸ’¡ MQTT FastAPI ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®URL (iot_backend.py ãŒãƒãƒ¼ãƒˆ8000ã§å‹•ä½œ)
const MQTT_API_URL = "http://127.0.0.1:8000/control"; 

/* ---------- DOM ---------- */
const statusArea = document.getElementById('status-area');
const resetBtn = document.getElementById('resetBtn');
const input = document.getElementById('messageInput');
const modeIndicator = document.getElementById('modeIndicator');
const transcriptBox = document.getElementById('transcript');
const ui = document.getElementById('ui'); 
const tapArea = document.getElementById('tapArea'); 



let audioContext, analyser, mediaStream;
let isRecording = false; // éŸ³å£°èªè­˜ãŒã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‹ã©ã†ã‹
let recognition = null; // Web Speech API SpeechRecognition Object

/* ---------- UI helpers ---------- */
function status(msg){ statusArea.textContent = msg }

/* ---------- Speech Recognition (Browser STT) & Audio Init ---------- */

/**
Â * Web Speech APIã«ã‚ˆã‚‹éŸ³å£°èªè­˜ã‚’é–‹å§‹ã—ã¾ã™ã€‚
Â * ã“ã®é–¢æ•°ã¯ã€ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ãŒæˆåŠŸã—ã€audioContextãŒæº–å‚™ã§ãã¦ã‹ã‚‰å‘¼ã³å‡ºã•ã‚Œã¾ã™ã€‚
Â */
function startBrowserRecognition() {
Â  Â  // æ—¢ã«å®Ÿè¡Œä¸­ã®å ´åˆã¯ä½•ã‚‚ã—ãªã„
Â  Â  if (isRecording) return;
Â  Â  
Â  Â  if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
Â  Â  Â  Â  status('Error: Speech Recognition not supported in this browser.');
Â  Â  Â  Â  return;
Â  Â  }

Â  Â  // æ—¢å­˜ã®èªè­˜ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ã‚¯ãƒªã‚¢
Â  Â  if (recognition) {
Â  Â  Â  Â  recognition.stop();
Â  Â  Â  Â  recognition = null;
Â  Â  }

Â  Â  recognition = new (window.webkitSpeechRecognition || window.SpeechRecognition)();

Â  Â  // é€£ç¶šèªè­˜ãƒ¢ãƒ¼ãƒ‰ (ç™ºè©±ã®åˆ‡ã‚Œç›®ã§è‡ªå‹•åœæ­¢)
Â  Â  recognition.continuous = false; 
Â  Â  recognition.interimResults = true; 
Â  Â  recognition.lang = 'ja-JP';

Â  Â  recognition.onstart = () => {
Â  Â  Â  Â  isRecording = true;
Â  Â  Â  Â  status('Listening...');
Â  Â  Â  Â  input.value = 'è©±ã—ã¦ã„ã¾ã™...';
Â  Â  };

Â  Â  recognition.onresult = (event) => {
Â  Â  Â  Â  let interimTranscript = '';
Â  Â  Â  Â  let finalTranscript = '';

Â  Â  Â  Â  for (let i = event.resultIndex; i < event.results.length; ++i) {
Â  Â  Â  Â  Â  Â  if (event.results[i].isFinal) {
Â  Â  Â  Â  Â  Â  Â  Â  finalTranscript += event.results[i][0].transcript;
Â  Â  Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  Â  Â  Â  interimTranscript += event.results[i][0].transcript;
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  }

Â  Â  Â  Â  transcriptBox.textContent = finalTranscript || interimTranscript;
Â  Â  Â  Â  input.value = finalTranscript || interimTranscript;
Â  Â  };

Â  Â  // ğŸ’¡ ç™ºè©±çµ‚äº†ã¾ãŸã¯ã‚¨ãƒ©ãƒ¼æ™‚ã®è‡ªå‹•å†ã‚¹ã‚¿ãƒ¼ãƒˆãƒ­ã‚¸ãƒƒã‚¯
Â  Â  const restartRecognition = () => {
Â  Â  Â  Â  status('Recognition stopped. Restarting...');
Â  Â  Â  Â  setTimeout(() => {
Â  Â  Â  Â  Â  Â  try {
Â  Â  Â  Â  Â  Â  Â  Â  recognition.start();
Â  Â  Â  Â  Â  Â  } catch (e) {
Â  Â  Â  Â  Â  Â  Â  Â  // æ—¢ã«å®Ÿè¡Œä¸­ã®å ´åˆã®ã‚¨ãƒ©ãƒ¼ã‚’ç„¡è¦–
Â  Â  Â  Â  Â  Â  Â  Â  if (e.name !== 'InvalidStateError') {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  console.warn('Recognition start failed:', e);
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  }, 500); 
Â  Â  };
Â  Â  
Â  Â  recognition.onend = () => {
Â  Â  Â  Â  isRecording = false;
Â  Â  Â  Â  
Â  Â  Â  Â  const finalPrompt = transcriptBox.textContent.trim();
Â  Â  Â  Â  
Â  Â  Â  Â  if (finalPrompt && finalPrompt.length > 1 && !finalPrompt.startsWith("ã‚¤ãƒã‚¸ãƒŠãƒªãƒ¼ãƒŠãƒ³ãƒãƒ¼ é€šç§°GAIã‚¤ãƒã•ã‚“AIå¿œç­”:")) { // çŸ­ã™ãã‚‹ç™ºè©±ã‚„AIå¿œç­”ãƒ†ã‚­ã‚¹ãƒˆã‚’ç„¡è¦–
Â  Â  Â  Â  Â  Â  status('Processing response...');
Â  Â  Â  Â  Â  Â  processRecognitionResult(finalPrompt).finally(() => {
Â  Â  Â  Â  Â  Â  Â  Â  restartRecognition(); // å‡¦ç†å¾Œã«å†ã‚¹ã‚¿ãƒ¼ãƒˆ
Â  Â  Â  Â  Â  Â  });
Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  Â  // èªè­˜çµæœãŒãªã„å ´åˆã¯å³åº§ã«å†ã‚¹ã‚¿ãƒ¼ãƒˆ
Â  Â  Â  Â  Â  Â  transcriptBox.textContent = '';
Â  Â  Â  Â  Â  Â  input.value = 'è©±ã—ã‹ã‘ã¦ãã ã•ã„...';
Â  Â  Â  Â  Â  Â  restartRecognition();
Â  Â  Â  Â  }
Â  Â  };

Â  Â  recognition.onerror = (event) => {
Â  Â  Â  Â  isRecording = false;
Â  Â  Â  Â  console.error('Speech Recognition Error:', event.error);
Â  Â  Â  Â  
Â  Â  Â  Â  // ğŸ’¡ ä¿®æ­£ç®‡æ‰€: 'aborted' ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã‚‚å†ã‚¹ã‚¿ãƒ¼ãƒˆã™ã‚‹ã‚ˆã†ã«ä¿®æ­£
Â  Â  Â  Â  if (event.error !== 'no-speech' && event.error !== 'aborted') {
Â  Â  Â  Â  Â  Â  // 'not-allowed', 'audio-capture' ãªã©ã®ã‚¨ãƒ©ãƒ¼ã§å†ã‚¹ã‚¿ãƒ¼ãƒˆã‚’è©¦ã¿ã‚‹
Â  Â  Â  Â  Â  Â  restartRecognition();
Â  Â  Â  Â  } else if (event.error === 'no-speech' || event.error === 'network' || event.error === 'aborted') {
Â  Â  Â  Â  Â  Â  // ç„¡éŸ³ã‚¨ãƒ©ãƒ¼ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ã€ã¾ãŸã¯è‡ªå‹•ä¸­æ–­ã‚¨ãƒ©ãƒ¼ã®å ´åˆã€UIã‚’ãƒªã‚»ãƒƒãƒˆã—ã¦å†ã‚¹ã‚¿ãƒ¼ãƒˆ
Â  Â  Â  Â  Â  Â  transcriptBox.textContent = '';
Â  Â  Â  Â  Â  Â  input.value = 'è©±ã—ã‹ã‘ã¦ãã ã•ã„...';
Â  Â  Â  Â  Â  Â  restartRecognition();
Â  Â  Â  Â  }
Â  Â  Â  Â  // 'not-allowed'ã®å ´åˆã¯ä½•ã‚‚ã—ãªã„ï¼ˆãƒã‚¤ã‚¯è¨±å¯ãŒãªã„ãŸã‚ï¼‰
Â  Â  };

Â  Â  // æœ€åˆã®ã‚¹ã‚¿ãƒ¼ãƒˆ
Â  Â  try {
Â  Â  Â  Â  recognition.start();
Â  Â  } catch (e) {
Â  Â  Â  Â  console.warn('Initial recognition start failed:', e);
Â  Â  }
}

/**
Â * ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ã‚’è¦æ±‚ã—ã€AudioContextã€æ³¢å½¢åˆ†æã€ãŠã‚ˆã³STTã‚’è¨­å®šã™ã‚‹
Â */
async function initAudioAndSTT(){
Â  Â  // æ—¢ã«åˆæœŸåŒ–æ¸ˆã¿ã®å ´åˆã¯STTã ã‘å†ã‚¹ã‚¿ãƒ¼ãƒˆ
Â  Â  if(analyser) {
Â  Â  Â  Â  startBrowserRecognition();
Â  Â  Â  Â  return;
Â  Â  }
Â  Â  status('Requesting microphone access...');

Â  Â  try {
Â  Â  Â  Â  // 1. AudioContextã®åˆæœŸåŒ–
Â  Â  Â  Â  audioContext = new (window.AudioContext || window.webkitAudioContext)();
Â  Â  Â  Â  analyser = audioContext.createAnalyser();
Â  Â  Â  Â  analyser.fftSize = 2048;
Â  Â  Â  Â  
Â  Â  Â  Â  // 2. ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹
Â  Â  Â  Â  mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
Â  Â  Â  Â  const sourceNode = audioContext.createMediaStreamSource(mediaStream);
Â  Â  Â  Â  
Â  Â  Â  Â  // 3. æ¥ç¶šï¼ˆã‚½ãƒ¼ã‚¹ -> ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ï¼‰
Â  Â  Â  Â  sourceNode.connect(analyser);

Â  Â  Â  Â  // 4. ãƒ–ãƒ©ã‚¦ã‚¶STTã®é–‹å§‹
Â  Â  Â  Â  startBrowserRecognition();

Â  Â  Â  Â  status('Listening...');
Â  Â  } catch (e) {
Â  Â  Â  Â  console.error('Audio initialization failed:', e);
Â  Â  Â  Â  status('Error: Microphone access denied or failed to initialize.');
Â  Â  }
}

/**
Â * ğŸ’¡ æ–°è¦è¿½åŠ : FastAPI/MQTTãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«ã‚³ãƒãƒ³ãƒ‰ã‚’é€ä¿¡ã™ã‚‹é–¢æ•°
Â */
async function sendIoTCommand(command) {
Â  Â  status(`Executing IoT command: ${command}...`);
Â  Â  transcriptBox.textContent = `IoTã‚³ãƒãƒ³ãƒ‰: ${command} ã‚’å®Ÿè¡Œä¸­...`;
Â  Â  
Â  Â  try {
Â  Â  Â  Â  const response = await fetch(MQTT_API_URL, {
Â  Â  Â  Â  Â  Â  method: 'POST',
Â  Â  Â  Â  Â  Â  headers: {
Â  Â  Â  Â  Â  Â  Â  Â  'Content-Type': 'application/json'
Â  Â  Â  Â  Â  Â  },
Â  Â  Â  Â  Â  Â  body: JSON.stringify({ command: command })
Â  Â  Â  Â  });

Â  Â  Â  Â  const data = await response.json();

Â  Â  Â  Â  if (response.ok) {
Â  Â  Â  Â  Â  Â  // æˆåŠŸ
Â  Â  Â  Â  Â  Â  const successMsg = `æ‰¿çŸ¥ã—ã¾ã—ãŸã€‚${command === 'ON' ? 'é›»æ°—ã‚’ã¤ã‘ã¾ã—ãŸ' : 'é›»æ°—ã‚’æ¶ˆã—ã¾ã—ãŸ'}ã€‚`;
Â  Â  Â  Â  Â  Â  console.log("IoT Success:", data);
Â  Â  Â  Â  Â  Â  speak(successMsg);
Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  Â  // å¤±æ•— (HTTP 4xx/5xx ã‚¨ãƒ©ãƒ¼)
Â  Â  Â  Â  Â  Â  const detail = data.detail || "ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼";
Â  Â  Â  Â  Â  Â  const errorMsg = `ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚IoTã‚³ãƒãƒ³ãƒ‰ '${command}' ã®å®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°: ${detail}`;
Â  Â  Â  Â  Â  Â  console.error("IoT Error:", data);
Â  Â  Â  Â  Â  Â  speak(errorMsg);
Â  Â  Â  Â  }
Â  Â  } catch (error) {
Â  Â  Â  Â  // ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ãªã©
Â  Â  Â  Â  const networkErrorMsg = `ğŸ”´ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼: IoTãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“ (${error.message})`;
Â  Â  Â  Â  console.error("IoT Network Error:", error);
Â  Â  Â  Â  speak(networkErrorMsg);
Â  Â  }
}


/* ---------- çµ±åˆã•ã‚ŒãŸãƒ¡ã‚¤ãƒ³å‡¦ç†é–¢æ•° (IoT or LLM) ---------- */

async function processRecognitionResult(finalPrompt) {
Â  Â  // 1. IoTã‚³ãƒãƒ³ãƒ‰ã®åˆ¤å®šã¨æŒ¯ã‚Šåˆ†ã‘
Â  Â  const lowerPrompt = finalPrompt.toLowerCase();
Â  Â  let iotCommand = null;

Â  Â  if ((lowerPrompt.includes('ãƒ©ã‚¤ãƒˆ') || lowerPrompt.includes('é›»æ°—')) && (lowerPrompt.includes('ã¤ã‘') || lowerPrompt.includes('ã‚ªãƒ³') || lowerPrompt.includes('ç‚¹ã‘'))) {
Â  Â  Â  Â  iotCommand = 'ON';
Â  Â  } else if ((lowerPrompt.includes('ãƒ©ã‚¤ãƒˆ') || lowerPrompt.includes('é›»æ°—')) && (lowerPrompt.includes('ã‘ã—') || lowerPrompt.includes('ã‚ªãƒ•') || lowerPrompt.includes('æ¶ˆã—'))) {
Â  Â  Â  Â  iotCommand = 'OFF';
Â  Â  }

Â  Â  if (iotCommand) {
Â  Â  Â  Â  // ğŸ’¡ ä¿®æ­£: ãƒ€ãƒŸãƒ¼ã§ã¯ãªãã€å®Ÿéš›ã®IoTã‚³ãƒãƒ³ãƒ‰é€ä¿¡é–¢æ•°ã‚’å‘¼ã³å‡ºã™
Â  Â  Â  Â  await sendIoTCommand(iotCommand);
Â  Â  Â  Â  return; 
Â  Â  }
Â  Â  
Â  Â  // 2. LLMå¿œç­”ç”Ÿæˆï¼ˆIoTã‚³ãƒãƒ³ãƒ‰ã§ãªã‹ã£ãŸå ´åˆï¼‰
Â  Â  await generateAndSpeakResponse(finalPrompt);
}


/* ---------- LLM (Gemini) API & TTS é€£æº - **ä¿®æ­£ç®‡æ‰€** ---------- */
async function generateAndSpeakResponse(prompt) {
Â  Â  status('Generating response (via FastAPI)...');
Â  Â  
Â  Â  // ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã€ŒAIå¿œç­”:ã€ã¨ã„ã†ãƒ†ã‚­ã‚¹ãƒˆã‚’è©±ã—ãŸå ´åˆã€ãã‚Œã‚’é™¤å¤–ã™ã‚‹
Â  Â  const cleanedPrompt = prompt.replace(/^ã‚¤ãƒã‚¸ãƒŠãƒªãƒ¼ãƒŠãƒ³ãƒãƒ¼ é€šç§°GAIã‚¤ãƒã•ã‚“AIå¿œç­”:\s*/, '').trim();
Â  Â  if (!cleanedPrompt) {
Â  Â  Â  Â  return; 
Â  Â  }

// Â  Â  // ğŸ’¡ Google APIã®ä»£ã‚ã‚Šã«ã€FastAPIãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«æ¥ç¶šã™ã‚‹ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰
// Â  Â  const payload = {
// Â  Â  Â  Â  prompt: cleanedPrompt,
// Â  Â  Â  Â  max_length: 1000 // ã‚µãƒ¼ãƒãƒ¼å´ã§å‡¦ç†
// Â  Â  };
const systemInstruction = "ã‚ãªãŸã¯ã€Œã‚¤ãƒã‚¸ãƒŠãƒªãƒ¼ãƒŠãƒ³ãƒãƒ¼ é€šç§°GAIã‚¤ãƒã•ã‚“ã€ã¨ã„ã†åå‰ã®KS-903model8800-a1-90dã¨ã„ã†éŸ³å£°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«æ—¥æœ¬èªã§ã€ç°¡æ½”ã‹ã¤ä¸å¯§ã«ç­”ãˆã¦ãã ã•ã„ã€‚";

    const payload = {
        prompt: cleanedPrompt,
// Â  Â  Â  Â  max_length: 1000 // ã‚µãƒ¼ãƒãƒ¼å´ã§å‡¦ç†
        contents: [{ parts: [{ text: cleanedPrompt }] }],
        systemInstruction: { parts: [{ text: systemInstruction }] },
        tools: [{ "google_search": {} }], 
    };
Â  Â  
Â  Â  // æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè£… (FastAPIå‘¼ã³å‡ºã—ç”¨ã«èª¿æ•´)
Â  Â  const MAX_RETRIES = 3;
Â  Â  let responseText = "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚¤ãƒã‚¸ãƒŠãƒªãƒ¼ãƒŠãƒ³ãƒãƒ¼ é€šç§°GAIã‚¤ãƒã•ã‚“AIã®KS-903model8800-a1-90då¿œç­”ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚";

Â  Â  for (let i = 0; i < MAX_RETRIES; i++) {
Â  Â  Â  Â  try {
Â  Â  Â  Â  Â  Â  // ğŸ’¡ ä¿®æ­£: æ¥ç¶šå…ˆã‚’FastAPIãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«å¤‰æ›´
Â  Â  Â  Â  Â  Â  const response = await fetch(LLM_API_URL, {
Â  Â  Â  Â  Â  Â  Â  Â  method: 'POST',
Â  Â  Â  Â  Â  Â  Â  Â  headers: { 'Content-Type': 'application/json' },
Â  Â  Â  Â  Â  Â  Â  Â  body: JSON.stringify(payload)
Â  Â  Â  Â  Â  Â  });
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  // 429 (ãƒ¬ãƒ¼ãƒˆåˆ¶é™) ã¯é€šå¸¸FastAPIå´ã§ã¯ç™ºç”Ÿã—ãªã„ãŒã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ã¨ã—ã¦å‡¦ç†ã™ã‚‹
Â  Â  Â  Â  Â  Â  if (!response.ok) {
Â  Â  Â  Â  Â  Â  Â  Â  // FastAPIã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰è©³ç´°ã‚¨ãƒ©ãƒ¼ã‚’å–å¾—
Â  Â  Â  Â  Â  Â  Â  Â  const errorData = await response.json().catch(() => ({ detail: `HTTP ${response.status} Error.` }));
Â  Â  Â  Â  Â  Â  Â  Â  throw new Error(`FastAPI Error! Status: ${response.status}. Detail: ${errorData.detail}`);
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  const result = await response.json();
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  if (result && result.text) {
Â  Â  Â  Â  Â  Â  Â  Â  responseText = result.text;
Â  Â  Â  Â  Â  Â  Â  Â  break; // æˆåŠŸ
Â  Â  Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  Â  Â  Â  Â throw new Error("Empty response or invalid JSON structure from FastAPI.");
Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  } catch (e) {
Â  Â  Â  Â  Â  Â  console.error(`FastAPI call error on attempt ${i + 1}:`, e);
Â  Â  Â  Â  Â  Â  if (i === MAX_RETRIES - 1) {
Â  Â  Â  Â  Â  Â  Â  Â  // æœ€å¾Œã®è©¦è¡Œã§å¤±æ•—ã—ãŸå ´åˆ
Â  Â  Â  Â  Â  Â  Â  Â  responseText = "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚¤ãƒã‚¸ãƒŠãƒªãƒ¼ãƒŠãƒ³ãƒãƒ¼ é€šç§°GAIã‚¤ãƒã•ã‚“AIKS-903model8800-a1-90dã®å¿œç­”ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚Generaltebãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒãƒ¼ (ãƒãƒ¼ãƒˆ8001) ã®å®Ÿè¡ŒçŠ¶æ…‹ã¨APIã‚­ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚";
Â  Â  Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  Â  Â  Â  // å†è©¦è¡Œã®ãŸã‚ã«å¾…æ©Ÿ
Â  Â  Â  Â  Â  Â  Â  Â  const delay = 2 ** i * 1000 + Math.random() * 500;
Â  Â  Â  Â  Â  Â  Â  Â  await new Promise(resolve => setTimeout(resolve, delay));
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  }
Â  Â  }

Â  Â  status('Speaking response...');
Â  Â  speak(responseText); 
}

/* ---------- TTS (Speech Synthesis) ---------- */
const synth = window.speechSynthesis;

function speak(text){ 
Â  Â  if(!text) return; 
Â  Â  
Â  Â  // é€£ç¶šå‘¼ã³å‡ºã—æŠ‘åˆ¶ã¨ã‚­ãƒ£ãƒ³ã‚»ãƒ«å‡¦ç†
Â  Â  if(synth.speaking) synth.cancel(); 
Â  Â  
Â  Â  // å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆã‚’ transcriptBox ã«è¡¨ç¤º
Â  Â  transcriptBox.textContent = "ã‚¤ãƒã‚¸ãƒŠãƒªãƒ¼ãƒŠãƒ³ãƒãƒ¼ é€šç§°GAIã‚¤ãƒã•ã‚“AIå¿œç­”: " + text;
Â  Â  input.value = "ã‚¤ãƒã‚¸ãƒŠãƒªãƒ¼ãƒŠãƒ³ãƒãƒ¼ é€šç§°GAIã‚¤ãƒã•ã‚“AIå¿œç­”ä¸­...";

Â  Â  const u = new SpeechSynthesisUtterance(text); 
Â  Â  u.lang='ja-JP'; 
Â  Â  u.rate=1.0; 
Â  Â  u.onstart=()=>{ 
Â  Â  Â  Â  status('Speaking...'); 
Â  Â  Â  Â  input.value = "ã‚¤ãƒã‚¸ãƒŠãƒªãƒ¼ãƒŠãƒ³ãƒãƒ¼ é€šç§°GAIã‚¤ãƒã•ã‚“AIå¿œç­”ä¸­...";
Â  Â  }; 
Â  Â  u.onend=()=>{ 
Â  Â  Â  Â  // èª­ã¿ä¸Šã’çµ‚äº†å¾Œã€STTã®onendãƒ­ã‚¸ãƒƒã‚¯ã§å†ã‚¹ã‚¿ãƒ¼ãƒˆã•ã‚Œã‚‹ãŸã‚ã€ã“ã“ã§ã¯çŠ¶æ…‹ã‚’æˆ»ã™
Â  Â  Â  Â  status('Ready to listen...'); 
Â  Â  Â  Â  input.value = "è©±ã—ã‹ã‘ã¦ãã ã•ã„...";
Â  Â  }; 
Â  Â  u.onerror = (e) => {
Â  Â  Â  Â  console.error('TTS error:', e);
Â  Â  Â  Â  status('TTS Error. Ready to listen...');
Â  Â  Â  Â  input.value = "è©±ã—ã‹ã‘ã¦ãã ã•ã„...";
Â  Â  };

Â  Â  synth.speak(u); 
}


/* ---------- UI ãƒˆã‚°ãƒ«æ©Ÿèƒ½ (ç”»é¢ã‚¿ãƒƒãƒ—) ---------- */
let uiVisible = true;
tapArea.addEventListener('click', (e) => {
Â  Â  // è¨˜å…¥æ¬„ã‚„ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³ã¸ã®ã‚¿ãƒƒãƒ—ã¯ç„¡è¦–ã™ã‚‹
Â  Â  if (e.target.closest('#controls') || e.target.closest('#transcript')) {
Â  Â  Â  Â  return;
Â  Â  }

Â  Â  uiVisible = !uiVisible;
Â  Â  if (uiVisible) {
Â  Â  Â  Â  ui.style.opacity = 1; // ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¤ãƒ³
Â  Â  } else {
Â  Â  Â  Â  ui.style.opacity = 0; // ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¢ã‚¦ãƒˆ
Â  Â  }
});


/* ---------- Controls ---------- */
resetBtn.addEventListener('click', ()=>{ 
Â  Â  // STTã¨TTSã‚’å¼·åˆ¶åœæ­¢
Â  Â  if (recognition) {
Â  Â  Â  Â  recognition.stop();
Â  Â  Â  Â  recognition = null;
Â  Â  }
Â  Â  if(synth.speaking) synth.cancel(); 

Â  Â  input.value=''; 
Â  Â  transcriptBox.textContent=''; 
Â  Â  
Â  Â  // å†åº¦éŒ²éŸ³ã‚’é–‹å§‹
Â  Â  initAudioAndSTT();
Â  Â  status('Reset. Listening...'); 
});


/* ---------- Start-up ---------- */
window.onload = function() {
Â  Â  // 1. èµ·å‹•æ™‚ã«ãƒã‚¤ã‚¯åˆæœŸåŒ–ã¨STTã‚’è‡ªå‹•ã§é–‹å§‹
Â  Â  initAudioAndSTT();

    </script>
</body>
</html>
