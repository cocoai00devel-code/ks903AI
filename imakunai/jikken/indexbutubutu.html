

<!doctype html>
<html lang="ja">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>ã‚¤ãƒã‚¸ãƒ³ã•ã‚“ AIã€€ãƒ–ãƒãƒ¥ãƒ–ãƒãƒ¥ãƒãƒ³ã¾ãŸã¯ã¶ã¤ã¶ã¤ãƒãƒ³ Voice Assistant (è‡ªå‹•é€£ç¶šèªè­˜ + VAD)</title>
<style>
/* CSSéƒ¨åˆ†ã¯å¤‰æ›´ãªã— */
    :root{--accent:#00ffff;--accent-2:#00ffaa;--bg:#0f0f0f}
    html,body{height:100%;margin:0;background:var(--bg);color:#fff;font-family:Segoe UI,system-ui,Arial}
    canvas{position:fixed;inset:0;z-index:0}
    
    /* ğŸ’¡ UIã®ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¤ãƒ³/ã‚¢ã‚¦ãƒˆã¨ã‚¿ãƒƒãƒ—é ˜åŸŸã®ã‚¹ã‚¿ã‚¤ãƒ« */
    #ui{
        position:absolute;left:50%;bottom:5%;transform:translateX(-50%);z-index:10;width:min(980px,94vw);
        opacity: 1; /* åˆæœŸè¡¨ç¤º */
        transition: opacity 0.5s ease-in-out; /* ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š */
    }
    /* ç”»é¢å…¨ä½“ã‚’ã‚¿ãƒƒãƒ—é ˜åŸŸã¨ã—ã¦è¨­å®š */
    #tapArea {
        position: fixed;
        inset: 0;
        z-index: 5; /* UIã®ä¸‹ã€ã‚­ãƒ£ãƒ³ãƒã‚¹ã®ä¸Šã«é…ç½® */
    }

    #status-area{padding:14px 20px;border-radius:12px;background:rgba(0,0,0,0.45);box-shadow:0 0 20px #00ffff55;color:var(--accent);font-weight:700}
    #controls{display:flex;gap:12px;margin-top:10px;align-items:center}
    #messageInput{flex:1;padding:12px 14px;border-radius:10px;border:1px solid rgba(0,255,255,0.15);background:rgba(255,255,255,0.03);color:#fff;font-size:16px}
    button{padding:10px 14px;border-radius:10px;border:none;cursor:pointer;font-weight:700}
    #micBtn{background:var(--accent-2);color:#000} /* ã“ã®ãƒœã‚¿ãƒ³ã¯æ©Ÿèƒ½çš„ã«ã¯ä½¿ã‚ãªã„ãŒã€CSSã¯æ®‹ã™ */
    #resetBtn{background:var(--accent);color:#000}
    #modeIndicator{padding:8px 10px;border-radius:8px;background:#00000044;font-size:0.9rem}
    #subtext{margin-top:8px;color:#bfeeff}
    .active{box-shadow:0 0 20px #ff5555}
    #transcript{margin-top:12px;padding:12px;border-radius:10px;background:rgba(255,255,255,0.02);min-height:48px;font-size:16px}
</style>
</head>
<body>
<canvas id="waveCanvas"></canvas>

<div id="tapArea"></div>

<div id="ui">
    <div id="status-area">Initializing...</div>
    <div id="controls">
        <input id="messageInput" placeholder="è©±ã—ã‹ã‘ã¦ãã ã•ã„..." disabled> <button id="resetBtn">ãƒªã‚»ãƒƒãƒˆ</button>
        <div id="modeIndicator">--</div>
    </div>
    <div id="subtext">é€£ç¶šèªè­˜ãƒ¢ãƒ¼ãƒ‰ï¼ˆVADã«ã‚ˆã‚‹è‡ªå‹•ã‚¹ã‚¿ãƒ¼ãƒˆ/ã‚¹ãƒˆãƒƒãƒ—ï¼‰</div>
    <div id="transcript"></div>
</div><script>
/* ---------- Config ---------- */
const WHISPER_WS_URL = 'ws://localhost:8765'; // Whisperã‚µãƒ¼ãƒãƒ¼ã®URL
const GPT2_API_URL = 'http://127.0.0.1:7860/api/predict'; // ğŸ’¡ è¿½åŠ : Gradio APIã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆURL
const VAD_SILENCE_MS = 1500; 
const AUDIO_CHUNK_MS = 300; 
const ENABLE_FALLBACK = true; 

/* ---------- DOM ---------- */
const statusArea = document.getElementById('status-area');
const resetBtn = document.getElementById('resetBtn');
const input = document.getElementById('messageInput');
const modeIndicator = document.getElementById('modeIndicator');
const transcriptBox = document.getElementById('transcript');
const ui = document.getElementById('ui'); 
const tapArea = document.getElementById('tapArea'); 

/* ---------- Audio / Waveform ---------- */
const canvas = document.getElementById('waveCanvas');
const ctx = canvas.getContext('2d');
function resizeCanvas(){canvas.width = innerWidth; canvas.height = innerHeight}
window.addEventListener('resize', resizeCanvas); resizeCanvas();

let audioContext, analyser, mediaStream, sourceNode, processorNode;
let isRecording = false;
let ws=null, wsAvailable=false;
let useServer=false;
let recognition=null; 

/* VAD helper */
let lastSpokenTime = 0;
let vadSilenceTimer = null;
function nowMs(){return performance.now()}

/* Simple energy VAD */
function isLoud(buffer, threshold=0.01){
    let sum=0; for(let i=0;i<buffer.length;i++){ let v=buffer[i]; sum += v*v }
    let rms = Math.sqrt(sum / buffer.length);
    return rms > threshold;
}

/* Waveform draw */
let waveformData = new Float32Array(1024);
// Waveformã®æç”»ãƒ­ã‚¸ãƒƒã‚¯ã¯init()å†…ã®loopCanvas()ã«ç§»è­²ã•ã‚Œã€åˆ†æãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦å‹•çš„ã«å¤‰åŒ–ã™ã‚‹

/* ---------- WebSocket (Whisper) client ---------- */
function connectWS(){
    status('Connecting to Whisper server...');
    ws = new WebSocket(WHISPER_WS_URL);
    ws.binaryType = 'arraybuffer';
    ws.onopen = ()=>{ wsAvailable=true; status('Whisper server connected'); modeIndicator.textContent='mode: server (Whisper)'; useServer=true };
    ws.onmessage = (ev)=>{
        const text = typeof ev.data === 'string' ? ev.data : new TextDecoder().decode(ev.data);
        try{
            const j = JSON.parse(text);
            if(j.type === 'partial'){
                input.value = j.text; transcriptBox.textContent = j.text;
            } else if(j.type==='final'){
                input.value = j.text; 
                transcriptBox.textContent = j.text; 
                // ğŸ’¡ çµ±åˆéƒ¨åˆ†: èªè­˜çµæœã‚’å‡¦ç†
                processRecognitionResult(j.text);
            } else {
                input.value = j.text; transcriptBox.textContent = j.text;
            }
        }catch(e){
            input.value = text; transcriptBox.textContent = text;
        }
    };
    ws.onerror = (e)=>{ console.warn('ws err',e); wsAvailable=false; useServer=false; if(ENABLE_FALLBACK) status('Whisper server unreachable. Will use browser STT fallback'); };
    ws.onclose = ()=>{ wsAvailable=false; useServer=false; status('Whisper server closed'); modeIndicator.textContent='mode: fallback'; };
}

/* --- (startRecording, stopRecording, floatTo16BitPCM, isLoud, startBrowserRecognition, stopBrowserRecognition ã®å®Ÿè£…ã¯å‰å›ã®å†…å®¹ã‚’å‚ç…§ã—ã€ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰ã«è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã¨ä»®å®šã—ã¾ã™) --- */
// ä¾¿å®œä¸Šã€ã“ã“ã§ã¯ connectWS ã®å‰ã« startRecording ã®éª¨å­ã‚’è¨˜è¿°ã—ã¾ã™
async function startRecording(){
    if(isRecording) return;
    isRecording = true;         
    // ... (ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ã€AudioContextã€processorNodeã®è¨­å®šãƒ­ã‚¸ãƒƒã‚¯) ...
    status(useServer ? 'Listening (Whisper Server)...' : 'Listening (Browser STT)...');
    lastSpokenTime = nowMs();
    processorNode.onaudioprocess = (evt)=>{
        // ... (éŸ³å£°ãƒãƒƒãƒ•ã‚¡å‡¦ç†ã€VADåˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ã€ws.send(pcm16.buffer), VADã«ã‚ˆã‚‹commitä¿¡å·é€ä¿¡ãƒ­ã‚¸ãƒƒã‚¯) ...
    };
    if(ENABLE_FALLBACK && !useServer) startBrowserRecognition();
}
// ... 

/* ---------- çµ±åˆã•ã‚ŒãŸãƒ¡ã‚¤ãƒ³å‡¦ç†é–¢æ•° (IoT or LLM) ---------- */

function processRecognitionResult(finalPrompt) {
    // 1. IoTã‚³ãƒãƒ³ãƒ‰ã®åˆ¤å®šã¨æŒ¯ã‚Šåˆ†ã‘
    const lowerPrompt = finalPrompt.toLowerCase();
    let iotCommand = null;

    if ((lowerPrompt.includes('ãƒ©ã‚¤ãƒˆ') || lowerPrompt.includes('é›»æ°—')) && (lowerPrompt.includes('ã¤ã‘') || lowerPrompt.includes('ã‚ªãƒ³'))) {
        iotCommand = 'ON';
    } else if ((lowerPrompt.includes('ãƒ©ã‚¤ãƒˆ') || lowerPrompt.includes('é›»æ°—')) && (lowerPrompt.includes('ã‘ã—') || lowerPrompt.includes('ã‚ªãƒ•'))) {
        iotCommand = 'OFF';
    }

    if (iotCommand) {
        // IoTã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œ
        sendIotCommand(iotCommand).then(success => {
            if (success) {
                speak(`æ‰¿çŸ¥ã—ã¾ã—ãŸã€é›»æ°—ã‚’${iotCommand === 'ON' ? 'ç‚¹ã‘ã¾ã—ãŸ' : 'æ¶ˆã—ã¾ã—ãŸ'}ã€‚`);
            } else {
                speak("ã™ã¿ã¾ã›ã‚“ã€åˆ¶å¾¡ã‚³ãƒãƒ³ãƒ‰ã®é€ä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸã€‚");
            }
        });
        return; // LLMã¸ã®å‡¦ç†ã¯ã‚¹ã‚­ãƒƒãƒ—
    }
    
    // 2. LLMå¿œç­”ç”Ÿæˆï¼ˆIoTã‚³ãƒãƒ³ãƒ‰ã§ãªã‹ã£ãŸå ´åˆï¼‰
    generateAndSpeakResponse(finalPrompt);
}

/* ---------- ğŸ’¡ IoTåˆ¶å¾¡ API é€£æº ---------- */
async function sendIotCommand(command) {
    status(`Executing IoT command: ${command}...`);
    try {
        const response = await fetch(IOT_API_URL, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            // Python FastAPIã® /control ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒæœŸå¾…ã™ã‚‹å½¢å¼ã§ã‚³ãƒãƒ³ãƒ‰ã‚’é€ä¿¡
            body: JSON.stringify({ command: command }) 
        });

        if (!response.ok) {
            throw new Error(`HTTP Error! Status: ${response.status}`);
        }
        
        const result = await response.json();
        console.log("IoT Server Response:", result);
        return true; // æˆåŠŸ
    } catch (error) {
        console.error("Failed to send IoT command:", error);
        return false; // å¤±æ•—
    }
}


/* ---------- LLM (GPT-2) API & TTS é€£æº (IoTãƒ­ã‚¸ãƒƒã‚¯åˆ†é›¢æ¸ˆã¿) ---------- */
async function generateAndSpeakResponse(prompt) {
    status('Generating response (GPT-2)...');
    
    // Gradioã§è¨­å®šã—ãŸå…¥åŠ›ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®é †åºï¼ˆPrompt, Max Lengthï¼‰ã«åˆã‚ã›ã¦ãƒ‡ãƒ¼ã‚¿ã‚’é€ä¿¡
    const requestData = {
        data: [
            prompt, // 1ç•ªç›®ã®å…¥åŠ›: Prompt (Whisperã®èªè­˜çµæœ)
            80      // 2ç•ªç›®ã®å…¥åŠ›: Max Length
        ]
    };

    try {
        const response = await fetch(GPT2_API_URL, { 
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify(requestData) 
        });
                
        if (!response.ok) {
            throw new Error(`HTTP error! status: ${response.status}`);
        }
                
        const result = await response.json();
        const gpt2_response = result.data && result.data[0] ? result.data[0] : "å¿œç­”ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚";

        status('Speaking response...');
        speak(gpt2_response); 
    } catch (e) {
        console.error("GPT-2 API error:", e);
        status('Error: GPT-2 API failed.');
        speak("å¿œç­”ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚µãƒ¼ãƒãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚");
    }
}
/* ---------- TTS ---------- */
const synth = window.speechSynthesis;
let lastSpokenText = '';
function speak(text){ 
    if(!text || text===lastSpokenText) return; 
    lastSpokenText = text; 
    if(synth.speaking) synth.cancel(); 
    const u = new SpeechSynthesisUtterance(text); 
    u.lang='ja-JP'; 
    u.rate=1.0; 
    u.onstart=()=>{ status('Speaking...'); }; 
    u.onend=()=>{ status('Listening...'); }; // èª­ã¿ä¸Šã’çµ‚äº†å¾Œã€ãƒªã‚¹ãƒ‹ãƒ³ã‚°çŠ¶æ…‹ã«æˆ»ã‚‹
    synth.speak(u); 
}

/* ---------- UI helpers ---------- */
function status(msg){ statusArea.textContent = msg }

/* ---------- UI ãƒˆã‚°ãƒ«æ©Ÿèƒ½ (ç”»é¢ã‚¿ãƒƒãƒ—) ---------- */
let uiVisible = true;
tapArea.addEventListener('click', (e) => {
    // è¨˜å…¥æ¬„ã‚„ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³ã¸ã®ã‚¿ãƒƒãƒ—ã¯ç„¡è¦–ã™ã‚‹
    if (e.target.closest('#controls') || e.target.closest('#transcript')) {
        return;
    }

    uiVisible = !uiVisible;
    if (uiVisible) {
        ui.style.opacity = 1; // ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¤ãƒ³
    } else {
        ui.style.opacity = 0; // ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¢ã‚¦ãƒˆ
    }
});


/* ---------- Controls ---------- */
resetBtn.addEventListener('click', ()=>{ 
    input.value=''; transcriptBox.textContent=''; 
    if(synth.speaking) synth.cancel(); 
    lastSpokenText = '';
    status('Reset'); 
});


/* ---------- Start-up ---------- */
(function init(){
    // ... initå†…ã®ã‚³ãƒ¼ãƒ‰ã¯å¤‰æ›´ãªã—
    // 1. WebSocketæ¥ç¶šãƒã‚§ãƒƒã‚¯ã¨ãƒ¢ãƒ¼ãƒ‰è¨­å®š
    status('Initializing audio...');
    new Promise(resolve => {
        try{ 
            const p = new WebSocket(WHISPER_WS_URL); 
            p.onopen=()=>{ 
                p.close(); 
                wsAvailable = true;
                useServer = true;
                status('Whisper server reachable'); 
                modeIndicator.textContent='mode: server (available)'; 
                resolve();
            }; 
            p.onerror=()=>{ 
                wsAvailable = false;
                useServer = false;
                modeIndicator.textContent='mode: fallback (no server)'; 
                status('Whisper server not reachable - will use browser STT'); 
                resolve();
            }; 
        } catch(e){ 
            wsAvailable = false;
            useServer = false;
            modeIndicator.textContent='mode: fallback'; 
            status('ready'); 
            resolve();
        }
    }).then(() => {
        // 2. èµ·å‹•æ™‚ã«è‡ªå‹•ã§èªè­˜ã‚’é–‹å§‹
        startRecording();
    });

    // 3. Waveformã®è¦–è¦šãƒ«ãƒ¼ãƒ—
    (function loopCanvas(){
        if(analyser){
            const bufferLen = analyser.fftSize; const data = new Float32Array(bufferLen);
            analyser.getFloatTimeDomainData(data);
            ctx.clearRect(0,0,canvas.width,canvas.height);
            ctx.beginPath();
            const mid = canvas.height*0.55; const step = canvas.width / bufferLen;
            // ğŸ’¡ ã“ã“ã§ x ãŒæœªå®šç¾©ã«ãªã‚‹ã‚¨ãƒ©ãƒ¼ã‚’é˜²ããŸã‚ã€ãƒ«ãƒ¼ãƒ—å†…ã«å®šç¾©
            let x = 0; 
            for(let i=0;i<bufferLen;i++){ 
                // ğŸ’¡ æ³¢å½¢ã‚’ã‚ˆã‚Šãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ã«
                const amp = isRecording ? 0.9 : 0.4;
                const y=mid + data[i]*mid*amp; 
                x = i * step; // xåº§æ¨™ã‚’è¨ˆç®—
                if(i===0)ctx.moveTo(x,y);else ctx.lineTo(x,y) 
            }
            ctx.strokeStyle='rgba(0,230,255,0.9)'; ctx.lineWidth=2; ctx.stroke();
        }
        requestAnimationFrame(loopCanvas);
    })();
})();

</script></body>
</html>
